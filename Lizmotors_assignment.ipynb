{"cells":[{"cell_type":"markdown","id":"ho-Y11gjPRnv","metadata":{"id":"ho-Y11gjPRnv"},"source":["**Installing all the requirements**"]},{"cell_type":"code","execution_count":4,"id":"A6__GsxFmdIv","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":120284,"status":"ok","timestamp":1724679101815,"user":{"displayName":"Lakshay","userId":"16251128063007424511"},"user_tz":-330},"id":"A6__GsxFmdIv","outputId":"15b9be87-8d28-4b9f-e296-8202aea4981b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting git+https://github.com/huggingface/parler-tts.git (from -r requirements.txt (line 3))\n","  Cloning https://github.com/huggingface/parler-tts.git to /tmp/pip-req-build-vzrbn9e6\n","  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/parler-tts.git /tmp/pip-req-build-vzrbn9e6\n","  Resolved https://github.com/huggingface/parler-tts.git to commit 8e465f1b5fcd223478e07175cb40494d19ffbe17\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting openai-whisper (from -r requirements.txt (line 1))\n","  Downloading openai-whisper-20231117.tar.gz (798 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.6/798.6 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting pydub (from -r requirements.txt (line 2))\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n","Requirement already satisfied: triton\u003c3,\u003e=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper-\u003e-r requirements.txt (line 1)) (2.3.1)\n","Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper-\u003e-r requirements.txt (line 1)) (0.60.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper-\u003e-r requirements.txt (line 1)) (1.26.4)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper-\u003e-r requirements.txt (line 1)) (2.3.1+cu121)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper-\u003e-r requirements.txt (line 1)) (4.66.5)\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper-\u003e-r requirements.txt (line 1)) (10.3.0)\n","Collecting tiktoken (from openai-whisper-\u003e-r requirements.txt (line 1))\n","  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Collecting transformers\u003c=4.43.3,\u003e=4.43.0 (from parler_tts==0.2-\u003e-r requirements.txt (line 3))\n","  Downloading transformers-4.43.3-py3-none-any.whl.metadata (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from parler_tts==0.2-\u003e-r requirements.txt (line 3)) (0.1.99)\n","Collecting descript-audio-codec (from parler_tts==0.2-\u003e-r requirements.txt (line 3))\n","  Downloading descript_audio_codec-1.0.0-py3-none-any.whl.metadata (7.8 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers\u003c=4.43.3,\u003e=4.43.0-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (3.15.4)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers\u003c=4.43.3,\u003e=4.43.0-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (0.23.5)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers\u003c=4.43.3,\u003e=4.43.0-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (24.1)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers\u003c=4.43.3,\u003e=4.43.0-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers\u003c=4.43.3,\u003e=4.43.0-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers\u003c=4.43.3,\u003e=4.43.0-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (2.32.3)\n","Requirement already satisfied: safetensors\u003e=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers\u003c=4.43.3,\u003e=4.43.0-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (0.4.4)\n","Requirement already satisfied: tokenizers\u003c0.20,\u003e=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers\u003c=4.43.3,\u003e=4.43.0-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (0.19.1)\n","Collecting argbind\u003e=0.3.7 (from descript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3))\n","  Downloading argbind-0.3.9.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting descript-audiotools\u003e=0.7.2 (from descript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3))\n","  Downloading descript_audiotools-0.7.2-py2.py3-none-any.whl.metadata (3.4 kB)\n","Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from descript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (0.8.0)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from descript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (2.3.1+cu121)\n","Requirement already satisfied: llvmlite\u003c0.44,\u003e=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba-\u003eopenai-whisper-\u003e-r requirements.txt (line 1)) (0.43.0)\n","Requirement already satisfied: typing-extensions\u003e=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-\u003eopenai-whisper-\u003e-r requirements.txt (line 1)) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch-\u003eopenai-whisper-\u003e-r requirements.txt (line 1)) (1.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch-\u003eopenai-whisper-\u003e-r requirements.txt (line 1)) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-\u003eopenai-whisper-\u003e-r requirements.txt (line 1)) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-\u003eopenai-whisper-\u003e-r requirements.txt (line 1)) (2024.6.1)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch-\u003eopenai-whisper-\u003e-r requirements.txt (line 1))\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch-\u003eopenai-whisper-\u003e-r requirements.txt (line 1))\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch-\u003eopenai-whisper-\u003e-r requirements.txt (line 1))\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch-\u003eopenai-whisper-\u003e-r requirements.txt (line 1))\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch-\u003eopenai-whisper-\u003e-r requirements.txt (line 1))\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch-\u003eopenai-whisper-\u003e-r requirements.txt (line 1))\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch-\u003eopenai-whisper-\u003e-r requirements.txt (line 1))\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch-\u003eopenai-whisper-\u003e-r requirements.txt (line 1))\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch-\u003eopenai-whisper-\u003e-r requirements.txt (line 1))\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch-\u003eopenai-whisper-\u003e-r requirements.txt (line 1))\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch-\u003eopenai-whisper-\u003e-r requirements.txt (line 1))\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107-\u003etorch-\u003eopenai-whisper-\u003e-r requirements.txt (line 1))\n","  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: docstring-parser in /usr/local/lib/python3.10/dist-packages (from argbind\u003e=0.3.7-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (0.16)\n","Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (from descript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (0.12.1)\n","Collecting pyloudnorm (from descript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3))\n","  Downloading pyloudnorm-0.1.1-py3-none-any.whl.metadata (5.6 kB)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from descript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (6.4.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from descript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (1.13.1)\n","Collecting julius (from descript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3))\n","  Downloading julius-0.2.7.tar.gz (59 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting ffmpy (from descript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3))\n","  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from descript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (7.34.0)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from descript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (13.7.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from descript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (3.7.1)\n","Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (from descript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (0.10.2.post1)\n","Collecting pystoi (from descript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3))\n","  Downloading pystoi-0.4.1-py2.py3-none-any.whl.metadata (4.0 kB)\n","Collecting torch-stoi (from descript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3))\n","  Downloading torch_stoi-0.2.1-py3-none-any.whl.metadata (3.6 kB)\n","Collecting flatten-dict (from descript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3))\n","  Downloading flatten_dict-0.4.2-py2.py3-none-any.whl.metadata (9.2 kB)\n","Collecting markdown2 (from descript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3))\n","  Downloading markdown2-2.5.0-py2.py3-none-any.whl.metadata (2.2 kB)\n","Collecting randomname (from descript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3))\n","  Downloading randomname-0.2.1.tar.gz (64 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting protobuf\u003c3.20,\u003e=3.9.2 (from descript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3))\n","  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (787 bytes)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from descript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (2.17.0)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers\u003c=4.43.3,\u003e=4.43.0-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (3.3.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers\u003c=4.43.3,\u003e=4.43.0-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (3.7)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers\u003c=4.43.3,\u003e=4.43.0-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (2.0.7)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers\u003c=4.43.3,\u003e=4.43.0-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (2024.7.4)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003etorch-\u003eopenai-whisper-\u003e-r requirements.txt (line 1)) (2.1.5)\n","Requirement already satisfied: mpmath\u003c1.4,\u003e=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy-\u003etorch-\u003eopenai-whisper-\u003e-r requirements.txt (line 1)) (1.3.0)\n","Requirement already satisfied: six\u003c2.0,\u003e=1.12 in /usr/local/lib/python3.10/dist-packages (from flatten-dict-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (1.16.0)\n","Requirement already satisfied: setuptools\u003e=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (71.0.4)\n","Collecting jedi\u003e=0.16 (from ipython-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3))\n","  Using cached jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (0.7.5)\n","Requirement already satisfied: traitlets\u003e=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,\u003c3.1.0,\u003e=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (3.0.47)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (2.16.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (0.1.7)\n","Requirement already satisfied: pexpect\u003e4.3 in /usr/local/lib/python3.10/dist-packages (from ipython-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (4.9.0)\n","Requirement already satisfied: audioread\u003e=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (3.0.1)\n","Requirement already satisfied: scikit-learn\u003e=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (1.3.2)\n","Requirement already satisfied: joblib\u003e=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (1.4.2)\n","Requirement already satisfied: pooch\u003e=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (1.8.2)\n","Requirement already satisfied: soxr\u003e=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (0.4.0)\n","Requirement already satisfied: lazy-loader\u003e=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (0.4)\n","Requirement already satisfied: msgpack\u003e=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (1.0.8)\n","Requirement already satisfied: cffi\u003e=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (1.17.0)\n","Requirement already satisfied: contourpy\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (1.2.1)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (0.12.1)\n","Requirement already satisfied: fonttools\u003e=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (4.53.1)\n","Requirement already satisfied: kiwisolver\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (1.4.5)\n","Requirement already satisfied: pillow\u003e=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (9.4.0)\n","Requirement already satisfied: pyparsing\u003e=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (3.1.2)\n","Requirement already satisfied: python-dateutil\u003e=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (2.8.2)\n","Requirement already satisfied: future\u003e=0.16.0 in /usr/local/lib/python3.10/dist-packages (from pyloudnorm-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (1.0.0)\n","Collecting fire (from randomname-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3))\n","  Downloading fire-0.6.0.tar.gz (88 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.4/88.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: markdown-it-py\u003e=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (3.0.0)\n","Requirement already satisfied: absl-py\u003e=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (1.4.0)\n","Requirement already satisfied: grpcio\u003e=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (1.64.1)\n","Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (3.7)\n","Requirement already satisfied: tensorboard-data-server\u003c0.8.0,\u003e=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (0.7.2)\n","Requirement already satisfied: werkzeug\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (3.0.3)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi\u003e=1.0-\u003esoundfile-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (2.22)\n","Requirement already satisfied: parso\u003c0.9.0,\u003e=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi\u003e=0.16-\u003eipython-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (0.8.4)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py\u003e=2.2.0-\u003erich-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (0.1.2)\n","Requirement already satisfied: ptyprocess\u003e=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect\u003e4.3-\u003eipython-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (0.7.0)\n","Requirement already satisfied: platformdirs\u003e=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch\u003e=1.1-\u003elibrosa-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (4.2.2)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,\u003c3.1.0,\u003e=2.0.0-\u003eipython-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (0.2.13)\n","Requirement already satisfied: threadpoolctl\u003e=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn\u003e=0.20.0-\u003elibrosa-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (3.5.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire-\u003erandomname-\u003edescript-audiotools\u003e=0.7.2-\u003edescript-audio-codec-\u003eparler_tts==0.2-\u003e-r requirements.txt (line 3)) (2.4.0)\n","Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Downloading transformers-4.43.3-py3-none-any.whl (9.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading descript_audio_codec-1.0.0-py3-none-any.whl (26 kB)\n","Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Downloading descript_audiotools-0.7.2-py2.py3-none-any.whl (106 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m428.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n","Downloading flatten_dict-0.4.2-py2.py3-none-any.whl (9.7 kB)\n","Downloading markdown2-2.5.0-py2.py3-none-any.whl (47 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hUsing cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n","Downloading pyloudnorm-0.1.1-py3-none-any.whl (9.6 kB)\n","Downloading pystoi-0.4.1-py2.py3-none-any.whl (8.2 kB)\n","Downloading torch_stoi-0.2.1-py3-none-any.whl (7.8 kB)\n","Using cached jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n","Building wheels for collected packages: openai-whisper, parler_tts, argbind, julius, randomname, fire\n","  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801360 sha256=868c1edff77f0b2ba42f1a4219ecae0ae6d1e530d4c9279c101a430e9eef3208\n","  Stored in directory: /root/.cache/pip/wheels/d0/85/e1/9361b4cbea7dd4b7f6702fa4c3afc94877952eeb2b62f45f56\n","  Building wheel for parler_tts (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for parler_tts: filename=parler_tts-0.2-py3-none-any.whl size=77149 sha256=3de657ad387dabb6d8d0f0e29068c43883e575a1c8a639b6c3c077560722d82a\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-0weuboxe/wheels/08/9a/16/7c5e21266463d789fae86d97edb74efc55318f7946736cc645\n","  Building wheel for argbind (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for argbind: filename=argbind-0.3.9-py2.py3-none-any.whl size=11729 sha256=7dbad0d9e77400bc9b6826d3d8d1dfa8c3d59291a10a5addc23934966d5d13e0\n","  Stored in directory: /root/.cache/pip/wheels/ed/ab/ff/64eb14a776ae6525e1a7d6ad38b73ba020ecc4262d83a7889d\n","  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21869 sha256=ecadbca1cccfde807a995f73eeb45c40c56deb10da063ff2d9af3015f92767b5\n","  Stored in directory: /root/.cache/pip/wheels/b9/b2/05/f883527ffcb7f2ead5438a2c23439aa0c881eaa9a4c80256f4\n","  Building wheel for randomname (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for randomname: filename=randomname-0.2.1-py3-none-any.whl size=89195 sha256=8e59dab366e126f4fa31d253b32b3fd13ad7d006abb6f343af00b85f4f04edfe\n","  Stored in directory: /root/.cache/pip/wheels/10/50/8a/25f3820d26a431ffed1834d72ff2eb349123cf2b44c5a45727\n","  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fire: filename=fire-0.6.0-py2.py3-none-any.whl size=117030 sha256=ccd417b2252a2f88dd5b2868701a851a83617de6ac1a4ce893d4ddac68f105d6\n","  Stored in directory: /root/.cache/pip/wheels/d6/6d/5d/5b73fa0f46d01a793713f8859201361e9e581ced8c75e5c6a3\n","Successfully built openai-whisper parler_tts argbind julius randomname fire\n","Installing collected packages: pydub, protobuf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, markdown2, jedi, flatten-dict, fire, ffmpy, argbind, tiktoken, randomname, pystoi, pyloudnorm, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, transformers, openai-whisper, julius, torch-stoi, descript-audiotools, descript-audio-codec, parler_tts\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.20.3\n","    Uninstalling protobuf-3.20.3:\n","      Successfully uninstalled protobuf-3.20.3\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.42.4\n","    Uninstalling transformers-4.42.4:\n","      Successfully uninstalled transformers-4.42.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 24.4.1 requires protobuf\u003c5,\u003e=3.20, but you have protobuf 3.19.6 which is incompatible.\n","google-cloud-aiplatform 1.63.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,\u003c6.0.0dev,\u003e=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n","google-cloud-bigquery-connection 1.15.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,\u003c6.0.0dev,\u003e=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n","google-cloud-bigtable 2.26.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,\u003c6.0.0dev,\u003e=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n","google-cloud-functions 1.16.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,\u003c6.0.0dev,\u003e=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n","google-cloud-iam 2.15.2 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,\u003c6.0.0dev,\u003e=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n","google-cloud-language 2.13.4 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,\u003c6.0.0dev,\u003e=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n","google-cloud-pubsub 2.23.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,\u003c6.0.0dev,\u003e=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n","google-cloud-resource-manager 1.12.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,\u003c6.0.0dev,\u003e=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n","google-cloud-translate 3.15.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,\u003c6.0.0dev,\u003e=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n","googleapis-common-protos 1.63.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,\u003c6.0.0.dev0,\u003e=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n","grpc-google-iam-v1 0.13.1 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,\u003c6.0.0dev,\u003e=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n","tensorflow 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,\u003c5.0.0dev,\u003e=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n","tensorflow-datasets 4.9.6 requires protobuf\u003e=3.20, but you have protobuf 3.19.6 which is incompatible.\n","tensorflow-metadata 1.15.0 requires protobuf\u003c4.21,\u003e=3.20.3; python_version \u003c \"3.11\", but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed argbind-0.3.9 descript-audio-codec-1.0.0 descript-audiotools-0.7.2 ffmpy-0.4.0 fire-0.6.0 flatten-dict-0.4.2 jedi-0.19.1 julius-0.2.7 markdown2-2.5.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 openai-whisper-20231117 parler_tts-0.2 protobuf-3.19.6 pydub-0.25.1 pyloudnorm-0.1.1 pystoi-0.4.1 randomname-0.2.1 tiktoken-0.7.0 torch-stoi-0.2.1 transformers-4.43.3\n"]},{"data":{"application/vnd.colab-display-data+json":{"id":"ee4e07f5707c48c09dd4121ae475ed5f","pip_warning":{"packages":["google","transformers"]}}},"metadata":{},"output_type":"display_data"}],"source":["pip install -r requirements.txt"]},{"cell_type":"markdown","id":"YGpL7MExPd6a","metadata":{"id":"YGpL7MExPd6a"},"source":["**Loading \u0026 finding the audio channel and sampling rate**"]},{"cell_type":"code","execution_count":8,"id":"3e40986c-df82-4ae9-afd8-ac5126ad127c","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"elapsed":513,"status":"error","timestamp":1724680491928,"user":{"displayName":"Lakshay","userId":"16251128063007424511"},"user_tz":-330},"id":"3e40986c-df82-4ae9-afd8-ac5126ad127c","outputId":"4f376a9c-97b4-4739-9bb9-cab39b607bb8"},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'Recording (3).wav'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-8-17a868a1322c\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 2\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 2\u001b[0;31m \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Recording (3).wav\"\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# loading of audio file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"sample rate of original = {audio.frame_rate}\"\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# finding frame rate/sample rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m                                    \u001b[0;31m# finding audio channel :: 1 for mono \u0026 2 for stereo type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Audio channel = Mono\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydub/audio_segment.py\u001b[0m in \u001b[0;36mfrom_file\u001b[0;34m(cls, file, format, codec, parameters, start_second, duration, **kwargs)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 651\u001b[0;31m         \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fd_or_path_or_tempfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydub/utils.py\u001b[0m in \u001b[0;36m_fd_or_path_or_tempfile\u001b[0;34m(fd, mode, tempfile)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 60\u001b[0;31m         \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mclose_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Recording (3).wav'"]}],"source":["from pydub import AudioSegment\n","audio = AudioSegment.from_file(\"Recording (5).wav\")        # loading of audio file\n","print(f\"sample rate of original = {audio.frame_rate}\")     # finding frame rate/sample rate\n","if audio.channels == 1:                                    # finding audio channel :: 1 for mono \u0026 2 for stereo type\n","    print(\"Audio channel = Mono\")\n","else:\n","    print(\"Audio channel = Stereo\")"]},{"cell_type":"markdown","id":"11603145-cd16-43a7-a507-eddef3a7bc53","metadata":{"id":"11603145-cd16-43a7-a507-eddef3a7bc53"},"source":["### **De-sampling \u0026 setting audio channel to mono  **"]},{"cell_type":"code","execution_count":18,"id":"639fb444-82c7-49da-b9c9-ad6329cc614f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":471,"status":"ok","timestamp":1724659332658,"user":{"displayName":"Lakshay","userId":"16251128063007424511"},"user_tz":-330},"id":"639fb444-82c7-49da-b9c9-ad6329cc614f","outputId":"188a0503-baac-471a-f6df-bec694b12538"},"outputs":[{"data":{"text/plain":["\u003c_io.BufferedRandom name='pre-processed_audio.wav'\u003e"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["audio = audio.set_frame_rate(16000)                     # de-sampling the frame rate\n","audio = audio.set_channels(1)                           # setting audio channel to mono\n","audio.export(\"pre-processed_audio.wav\", format = \"wav\") # saving file as pre-processed"]},{"cell_type":"markdown","id":"jjYGMphqPyfH","metadata":{"id":"jjYGMphqPyfH"},"source":["**checking frame rate \u0026 audio channel of pre-processed file**"]},{"cell_type":"code","execution_count":19,"id":"a2428c52-cb2f-4176-9d95-05582da8ba78","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":470,"status":"ok","timestamp":1724659337483,"user":{"displayName":"Lakshay","userId":"16251128063007424511"},"user_tz":-330},"id":"a2428c52-cb2f-4176-9d95-05582da8ba78","outputId":"19b0385e-a467-4fe4-dfa8-c6a663c0e098"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sample rate \u0026 audio channel after pre-processing\n","Sample Rate = 16000 KHz\n","Audio channel = Mono\n"]}],"source":["audio = AudioSegment.from_file(\"pre-processed_audio.wav\")   # loading the newly made audio file\n","print(\"Sample rate \u0026 audio channel after pre-processing\")\n","print(f\"Sample Rate = {audio.frame_rate} KHz\")              # finding frame rate/sample rate\n","if audio.channels == 1:                                     # finding audio channel :: 1 for mono \u0026 2 for stereo type\n","    print(\"Audio channel = Mono\")\n","else:\n","    print(\"Audio channel = Stereo\")"]},{"cell_type":"markdown","id":"qVQ-4vGwQFpB","metadata":{"id":"qVQ-4vGwQFpB"},"source":["**TRanscribing for later evaluation**"]},{"cell_type":"code","execution_count":21,"id":"d04014da-2183-4f10-99f2-f45768d86538","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7225,"status":"ok","timestamp":1724659384575,"user":{"displayName":"Lakshay","userId":"16251128063007424511"},"user_tz":-330},"id":"d04014da-2183-4f10-99f2-f45768d86538","outputId":"b9d532a8-eb6c-4ffd-8b03-07c8da26c600"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n","  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"]},{"name":"stdout","output_type":"stream","text":[" can light bend around the corners.\n"]}],"source":["# convetring of the de-sampled audio for checking\n","text = model.transcribe(\"pre-processed_audio.wav\")\n","print(text[\"text\"])"]},{"cell_type":"markdown","id":"2a8650d7-041a-4a13-9d0b-54bd1b3feb8a","metadata":{"id":"2a8650d7-041a-4a13-9d0b-54bd1b3feb8a"},"source":["### VAD part: extracting the speeched part form the original part"]},{"cell_type":"code","execution_count":1,"id":"427b02bd-14f3-478f-917e-9c4afd48836a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21649,"status":"ok","timestamp":1724667970965,"user":{"displayName":"Lakshay","userId":"16251128063007424511"},"user_tz":-330},"id":"427b02bd-14f3-478f-917e-9c4afd48836a","outputId":"410f509c-0cba-4f25-fe3b-2250dc882cf7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading audio...\n","Performing VAD...\n","Starting transcription...\n","Transcription completed.\n","[0.00s - 2.00s]:  can light bend around the corners.\n"]}],"source":["import whisper\n","import numpy as np\n","from pydub import AudioSegment\n","import torch\n","\n","model = whisper.load_model(\"base\")     # loading whisper model\n","\n","# function to perfom the VAD identifying which parts of audio contains speech\n","def simple_vad(audio, threshold=0.5, min_silence_duration=0.3, sample_rate=16000):\n","\n","    frame_length = int(sample_rate * 0.01)  # number of smaples in the 10ms frame\n","    # Calculates the energy for each frame bys umming and squaring so to neglech any -ve values\n","    energy = np.array([sum(abs(audio[i:i+frame_length]**2)) for i in range(0, len(audio), frame_length)])\n","\n","    threshold = threshold * np.max(energy)    # dynamic threshold acocording to the lloudness/enegy values of the file\n","\n","    is_speech = energy \u003e threshold        # array to tell if particular part of speech have voice or not\n","\n","    # merge short silence gaps\n","    min_silence_frames = int(min_silence_duration / 0.01)\n","    for i in range(len(is_speech) - min_silence_frames):\n","        if sum(is_speech[i:i+min_silence_frames]) \u003e 0:\n","            is_speech[i:i+min_silence_frames] = True\n","\n","    return is_speech\n","\n","def transcribe_with_whisper_vad(audio_file, vad_threshold=0.5, min_silence_duration=0.3):\n","    print(\"Loading audio...\")\n","    audio = whisper.load_audio(audio_file)\n","\n","    print(\"Performing VAD...\")\n","    is_speech = simple_vad(audio, threshold=vad_threshold, min_silence_duration=min_silence_duration)\n","\n","    # Apply VAD mask to audio\n","    speech_audio = audio[np.repeat(is_speech, len(audio) // len(is_speech))]\n","\n","    print(\"Starting transcription...\")\n","    try:\n","        result = model.transcribe(speech_audio, fp16=False)\n","        print(\"Transcription completed.\")\n","        return result[\"segments\"]\n","    except Exception as e:\n","        print(f\"Error during transcription: {e}\")\n","        return []\n","\n","# Use the function\n","audio_file = \"pre-processed_audio.wav\"\n","transcribed_segments = transcribe_with_whisper_vad(audio_file, vad_threshold=0.01, min_silence_duration=0.3)\n","\n","if transcribed_segments:\n","    for segment in transcribed_segments:\n","        print(f\"[{segment['start']:.2f}s - {segment['end']:.2f}s]: {segment['text']}\")\n","        input_text = segment[\"text\"]\n","else:\n","    print(\"No transcribed segments were returned.\")"]},{"cell_type":"code","execution_count":23,"id":"932b2677-4a40-4717-be20-ed259d550d1a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":566,"status":"ok","timestamp":1724661036061,"user":{"displayName":"Lakshay","userId":"16251128063007424511"},"user_tz":-330},"id":"932b2677-4a40-4717-be20-ed259d550d1a","outputId":"eb76cd2c-9d9a-489b-92c9-786895a58999"},"outputs":[{"name":"stdout","output_type":"stream","text":[" can light bend around the corners.\n"]}],"source":["print(input_text)"]},{"cell_type":"markdown","id":"f00eac6d-82ed-4cb1-8104-d344c39d5136","metadata":{"id":"f00eac6d-82ed-4cb1-8104-d344c39d5136"},"source":["### USING LLM"]},{"cell_type":"code","execution_count":37,"id":"uJjD2gug3dKv","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11043,"status":"ok","timestamp":1724665947314,"user":{"displayName":"Lakshay","userId":"16251128063007424511"},"user_tz":-330},"id":"uJjD2gug3dKv","outputId":"58b75e38-18ae-44df-8b81-45afc11a289a"},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["Input:  can light bend around the corners.\n","Response: This is one of the big problems, that even if we think about straight lines and circles and things of the sort,  almost everything has to bend in some way for it to conform to the light.  That's why you can make things like balls spin around on top of each other\n"]}],"source":["from transformers import pipeline\n","\n","# Using gpt-2 medium LLM model\n","generator = pipeline('text-generation', model='gpt2-medium')\n","\n","# function to clean the output provided by model\n","def clean_response(result, prompt, question):\n","    clean_response = result.replace(prompt,\"\").replace(question,\"\").strip()    # removing content of prompt and question\n","    return clean_response\n","\n","# fucntionto get the response form llm\n","def generate_response(input_text):\n","    prompt = f\"give the simple direct answer without experimentaion for the question: {input_text}\"\n","    response = generator(prompt, max_length=80, num_return_sequences=1, truncation = True)\n","    return prompt, response[0]['generated_text']\n","\n","input = input_text\n","prompt, output = generate_response(input)\n","cleaned = clean_response(output, prompt, input)   # calling the clean_response function\n","print(f\"Input: {input}\")                          # printing input\n","print(f\"Response: {cleaned}\")                     # printin the cleaned output : by removing the prompt and question"]},{"cell_type":"markdown","id":"OUOusVvZQWtj","metadata":{"id":"OUOusVvZQWtj"},"source":["**TEXT TO SPEECH CONVERSION**"]},{"cell_type":"code","execution_count":38,"id":"kjjRmcQ93FrX","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":49},"executionInfo":{"elapsed":118108,"status":"ok","timestamp":1724666644971,"user":{"displayName":"Lakshay","userId":"16251128063007424511"},"user_tz":-330},"id":"kjjRmcQ93FrX"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n","  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0aa3c0de3c8c4668912dc2a03a79e0b7","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"]}],"source":["import torch\n","from parler_tts import ParlerTTSForConditionalGeneration\n","from transformers import AutoTokenizer\n","import soundfile as sf\n","\n","device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n","\n","# loads the pre-trained model parler tts\n","model = ParlerTTSForConditionalGeneration.from_pretrained(\"parler-tts/parler-tts-large-v1\").to(device)\n","\n","# laoding tokenizer to convert text into tokens\n","tokenizer = AutoTokenizer.from_pretrained(\"parler-tts/parler-tts-large-v1\")\n","\n","prompt = cleaned     # text output from LLM\n","# the adjustment of the voice type, pitch and speed can be adjusted with the help of description\n","description = \"Jon's voice is monotone yet slightly fast in delivery, with a very close recording that almost has no background noise.\"\n","\n","# to conovert the decription into tokens\n","input_ids = tokenizer(description, return_tensors=\"pt\").input_ids.to(device)\n","\n","# converts text into Tokens\n","prompt_input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n","\n","# inputs to the tts model\n","generation = model.generate(input_ids=input_ids, prompt_input_ids=prompt_input_ids)\n","\n","# preproceesing for the file to be saved\n","audio_arr = generation.cpu().numpy().squeeze()\n","\n","# saving the output as ausio file\n","sf.write(\"parler_tts_out1.wav\", audio_arr, model.config.sampling_rate)\n"]},{"cell_type":"markdown","id":"Z-eos7FCJ0O3","metadata":{"id":"Z-eos7FCJ0O3"},"source":[]}],"metadata":{"colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"077d513e7b0146128e3c41c12f82cd95":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d58162aaef74aebb518e45e85aae708":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e893e7cbfb84880b0a36cd34aa3ad76","placeholder":"​","style":"IPY_MODEL_84de24a5c07b458cb2ee66411ba70bf7","value":"Loading checkpoint shards: 100%"}},"6b75d55f202a4cddb845f8930e2d90d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7afb5f2125ab41d28fb6f233ca2fb2ca":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84de24a5c07b458cb2ee66411ba70bf7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9147063266804c638cf2cfd9449fcd41":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99cb474f55b14e73a800c52754be0c01":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_077d513e7b0146128e3c41c12f82cd95","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a602486014a540beb716c680159b0a26","value":2}},"9af6a48f2f82409fa4db688674983f7b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9147063266804c638cf2cfd9449fcd41","placeholder":"​","style":"IPY_MODEL_6b75d55f202a4cddb845f8930e2d90d8","value":" 2/2 [00:04\u0026lt;00:00,  2.31s/it]"}},"9e893e7cbfb84880b0a36cd34aa3ad76":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a602486014a540beb716c680159b0a26":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ff6cd075dbe14a50b2037c6445b8ed4a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1d58162aaef74aebb518e45e85aae708","IPY_MODEL_99cb474f55b14e73a800c52754be0c01","IPY_MODEL_9af6a48f2f82409fa4db688674983f7b"],"layout":"IPY_MODEL_7afb5f2125ab41d28fb6f233ca2fb2ca"}}}}},"nbformat":4,"nbformat_minor":5}